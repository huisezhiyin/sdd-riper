# 从传统编程转向大模型编程

## 0. 核心目标：从“代码产出者”变成“意图定义者”

这篇文档不是教你怎么把 `Ctrl+C` / `Ctrl+V` 换成“让 AI 写代码”，而是希望帮你完成一次根本性的职业角色转换：

**从“砌砖的工匠”进化为“画图纸的建筑师”。**

* **以前（代码中心）**：你的核心产出是**代码**。文档只是代码的“解释说明”，经常过期，也没人看。
* **以后（意图中心）**：你的核心产出是**清晰的意图（需求、约束、边界）**。代码只是由 AI 根据你的意图“编译”出来的**中间产物**。

在这个新范式下，我们不再以“写了多少行代码”论英雄，而是看：

1. **定义问题的清晰度**：你能否把模糊的想法，拆解成 AI 能听懂的精确指令？

2. **验收结果的敏锐度**：你能否一眼看出 AI 生成的代码里潜藏的逻辑漏洞？

3. **架构设计的掌控力**：你能否划定好安全边界，让 AI 在笼子里跳舞，而不是拆家？

**Code is cheap, Context is expensive.** （代码是廉价的，上下文才是昂贵的。）

不管你是程序员、产品经理还是测试，今天都应该**重新审视自己的核心竞争力**——不是你敲键盘的速度，而是你**定义软件形态**的能力。

越早完成这个思维切换，你就越不容易被“会用 AI 的人”替代，而是成为那个指挥 AI 千军万马的人。

不管你是程序员、测试还是产品、设计师，今天都应该**大用特用大模型写代码和文档**——越早把它融进日常工作，越不容易被“会用 AI 的人”替代。
当然这对我们这些已经在岗的人反而是个好消息：35 岁不一定要被“优化”，只要你会用模型，完全可以带着一队 AI 再干几十年。

这不是“立刻变成科幻世界”，而是一个可以在几个月内逐步感受到的现实改进。

**本文定位**：这是“觉醒篇”，只讲**为什么必须转向大模型编程**。方法论与可复现落地细节，请参考：  
[《AI 原生研发范式：从“代码中心”到“文档驱动”的演进》](<AI 原生研发范式：从“代码中心”到“文档驱动”的演进.md>)、  

---

## 1. 为什么要用大模型编程？

这不是“可选项”，而是**生产力基准的重构**。组织层面是生存指标，个人层面是能力模型迁移。你越早完成迁移，越不容易被“会用 AI 的人”替代。

大模型编程（LLM‑based Programming）的核心变化，是从关注 **“怎么做（How）”** 转向 **“需要什么（What）”**。

| 维度 | 传统方式 | 大模型编程带来的变化 |
| --- | --- | --- |
| **核心产出** | 代码 (Code) | **文档 (Document)** |
| 开发效率 | 人写代码、写测试、写文档 | **人定义意图，AI 生成文档与代码**，迭代速度明显加快 |
| 复杂逻辑 | 自己设计规则 / 算法 | 模型可以直接处理自然语言、日志、半结构化数据 |
| 门槛 | 需要熟练掌握语言/框架细节 | 用自然语言组织需求就能起步，代码细节更多交给模型 |
| 形态 | 一次写完一大坨代码 | **文档驱动**：生成文档 (AI) → 确认文档 (Human) → 生成代码 (AI) |

### 1.1 一个真实的转变经历

2023 年我还在微软时，GPT 刚刚兴起，大家已经开始尝试用大模型辅助处理一些代码问题。当时微软也在开发基于大模型的 Copilot，但受限于模型能力，功能还比较基础——只能帮忙添加注释、生成简单的单元测试，离真正“会写代码”还有很大差距。

然而短短一年多后，到了 2024 年底，我已经能用 Cursor 完成几乎所有的编码任务。过去一年多，我几乎没有真正“手写”过代码。不仅是我，我认识的很多程序员也是如此：日常工作的重心转向了系统设计、任务拆解和代码 Review，具体的实现则交给 AI 模型。

加入钉钉后，尽管我没有任何 Java 工程经验，依然能快速完成开发需求，产出的代码质量较高，也能很好地与团队现有的代码风格保持一致，全倚仗大模型的帮忙。

所以我非常确信：未来一定是大模型编码的世界，**学习大模型编程会像学习使用 IDE 一样，成为一项最基本的工程师技能**。

### 1.2 AI 编程带来的典型变化

| 任务类型 | 传统痛点 | AI 如何帮助 |
| --- | --- | --- |
| 补充单元测试 | 写测试枯燥重复，容易漏边界情况 | 自动生成常见 case，人负责补充业务特殊场景 |
| 重构遗留代码 | 改动牵一发动全身，不敢下手 | 先让 AI 分析依赖关系，生成重构方案，人审核后分步执行 |
| 理解陌生代码 | 翻来覆去看调用链，费时费力 | 直接问"这个模块做什么"，快速建立宏观认知 |
| 排查线上问题 | 日志堆积如山，定位根因困难 | 把错误栈和关键日志喂给 AI，快速得到可能原因 |
| 编写技术文档 | 需要整理思路、组织语言 | AI 生成文档骨架，人补充业务细节和决策背景 |
| 操作git | 需要自己手写commit，记忆和操作复杂的git指令 | AI一步到位，甄别需要提交哪些文件，ai自动生成commit，ai识别你的意图并且自动执行，比如回滚，合并等操作。 |

**注意**：以上场景的效率提升因人而异，关键是找到适合你的使用方式。

---

## 2. 人 + AI 结对编程：角色与好处

在传统软件工程里，“结对编程”是指两名开发者在同一台机器上协作：一人写代码（Driver），另一人盯整体设计和问题（Navigator），两人定期互换角色。收益主要在于：更早发现问题、更高代码质量、更快知识传递。

在大模型时代，可以把日常开发理解为一种“人 + AI 的新型结对编程”，只是角色从“人 + 人”变成了“人 + 模型”：

| 角色 | 职责 |
| --- | --- |
| **人类开发者** | **意图定义者 / 总编辑**：口述/定义需求、**审查并锁定** AI 生成的文档 (Sign-off)、验收最终结果 |
| **大模型 (AI)** | **执行者 / 创作者**：将意图转化为文档 (Drafting)、将文档转化为代码 (Coding)、自我纠错 |

**从“对话”到“协议”**：不要再把 AI 当成聊天机器人，把它当成一个**无状态的执行器**。

* **旧模式**：人脑 → 聊天框 → 代码（信息损耗极大）
* **新模式**：人脑 → **Spec 文档（锚点）** → AI → 代码

**核心心法：文档即太阳 (Sun Theory)**。不管对话进行到哪一步，AI 必须围绕文档公转。如果文档和代码冲突，**错的一定是代码**。
在这个模式下，"写代码"不再是你的唯一核心技能，你更多要擅长：

* 把需求翻译成清晰的 Prompt 和约束条件；
* 设计合理的步骤（先测试、再改代码、再回归）；
* 识别模型输出中的风险和幻觉，进行二次校对。

### 2.1 会后可以立即尝试的三件事

如果你还没有开始用 AI 编程，建议从以下低风险任务开始：

1. **给现有函数补充单元测试**

    * 选一个你熟悉的、逻辑相对简单的函数
    * 复制函数代码，对 AI 说："帮我为这个函数写 5 个覆盖边界情况的单元测试"
    * Review 生成的测试，修改不合理的 case
    * 运行测试，根据失败情况调整
    * **关键点**：明确说"只写测试，不改实现"

2. **理解陌生代码模块**

    * 找一个你不熟悉但需要了解的模块
    * 把核心类/函数代码给 AI，问："这个模块的主要职责是什么？关键流程是怎样的？"
    * 对比 AI 的回答和你自己的理解
    * **关键点**：把 AI 当成"导游"，帮你快速建立宏观认知

3. **编写技术方案文档**

    * 准备好需求描述和关键技术点
    * 让 AI 生成文档骨架："帮我写一份技术方案，包括背景、方案设计、风险和时间规划"
    * 补充业务细节和决策背景
    * **关键点**：AI 负责结构化，你负责业务内容

**预期时间**：每次 10-20 分钟，完成后你会对 AI 的能力边界有基本认知。

### 2.2 新的工作节奏：利用“认知缓冲”对抗“代码催眠”

在使用 AI 编程时，你会发现一个显著的变化：**键盘敲击声变少了，屏幕前的“等待”时间变多了（**我称之为“受迫性摸鱼”**）。**

* **以前（手写代码）**：大脑与手指同步高速运转，处于持续的“输出模式”。
* **现在（AI 生成）**：输入 Prompt 后，需要等待模型生成 30–60 秒，这期间你无法进行任何操作。

请注意：**这段“空窗期”不是在浪费时间，而是必要的“认知缓冲（Cognitive Buffer）”。**

在大模型高速生成大量代码时，人类很容易陷入**“代码催眠”**（Code Hypnosis）状态——即看着代码流淌觉得都对，实则大脑已经麻木，失去了批判性思维。

因此，强烈建议大家**“合法化”**这段等待时间：

1. **强制抽离**：在 AI 生成的几十秒内，允许视线短暂离开屏幕，或者清空大脑。这能让你在下一秒 Review 代码时，保持“像看陌生人代码一样”的敏锐度。

2. **思维预演**：利用这段间隙，跳出具体语法，在脑中预演逻辑的边界情况，而不是盯着光标发呆。

3. **节奏切换**：从“连续的高频输出”转变为“脉冲式的决策—休息—决策”。

**给团队的共识**： 在 AI 时代，**不要用“是否一直在敲键盘”来衡量工作饱和度**。一个对着屏幕静默思考、正在进行“认知重组”的工程师，往往比一个被 AI 带着跑的工程师，更能守住系统的安全底线。

---

## 3. 模型、工具与技巧

> 本节为可选参考，**不是本文主线**。若你只关心方向与方法论，可直接跳过，进入第 4 节或阅读“内功篇/教程”。

### 3.1 模型选择决策树

不要死记某个具体版本"最强"，模型迭代很快。
更实用的方式是按决策流程选择：
**使用口诀**：安全第一，复杂度第二，成本第三

**常见模型类型参考**：

| 类型 | 代表 | 适用场景 |
| --- | --- | --- |
| 外部高性能模型 | GPT 5.1、Claude 4.5、Gemini 3等 | 复杂重构、算法设计、整体架构建议等（前提是无敏感代码） |
| 私有化大模型 | Qwen3、GLM4.6 | 核心涉密代码、含用户数据的场景 |

**使用原则**：

* **先看安全等级，再选模型**：代码/数据越敏感，越应优先选内部合规模型
* 不要依赖单一模型的"个人口碑"，要结合**当前任务 + 实测效果**来选择

### 3.2 常见工具形态

| 工具 | 类型 | 简要说明 |
| --- | --- | --- |
| Cursor | IDE | 和大模型深度集成的编辑器，适合重度 AI 编程，但需注意仓库安全策略、费用和配额 |
| Claude Code / 各类 CLI | 命令行 | 把模型当成“远程结对伙伴”，适合本地仓库 + 终端工作流 |
| VSCode / JetBrains 插件 | IDE 插件 | 如 Aone Copilot、通义灵码等，适合集成到现有开发环境 |
| 内部工具 | 内部定制化大模型编程平台 | 通常集成了企业内网模型与合规配置，适合高安全场景 |

实际使用时，建议团队内统一几种“推荐组合”，例如：

* 非敏感仓库：VSCode + 外部高性能模型；
* 核心密级仓库：内部 CLI + 内部模型，不允许外发代码片段。

当然在安全可控和你舍得花钱的情况下，你可以使用中转站来使用世界上所有的大模型：

[https://openrouter.ai/: https://openrouter.ai/](https://openrouter.ai/)

[https://zenmux.ai/: https://zenmux.ai/](https://zenmux.ai/)

### 3.3 提示词工程：个人 Prompt 模板（简述）

提示词的关键不是“人设”，而是**约束**。最小模板只需要覆盖：引用文档、角色/目标、范围边界、工作方式与禁止事项。  
更完整的模板与示例已迁移到方法论篇的“进阶实践”附录：  
[《AI 原生研发范式：从“代码中心”到“文档驱动”的演进》](<AI 原生研发范式：从“代码中心”到“文档驱动”的演进.md>)。

### 3.4 进阶技巧：构建“会自我进化”的 SOP（简述）

把**提示词 + 脚本**打包成 Skill/SOP，能把经验沉淀为可复用资产；任务结束后让 AI 反向更新规则。  
详细流程与案例同样已迁移至方法论篇“进阶实践”附录：  
[《AI 原生研发范式：从“代码中心”到“文档驱动”的演进》](<AI 原生研发范式：从“代码中心”到“文档驱动”的演进.md>)。

这里还有一些 Claude skill 的例子，大家熟练后可以作为参考：

* [https://github.com/ComposioHQ/awesome-claude-skills](https://github.com/ComposioHQ/awesome-claude-skills)

## 4. 常见陷阱与对应策略

### 4.1 最大的敌人：上下文腐烂 (Context Decay)

很多人都有类似体验：**前 10 分钟如神助，30 分钟后像智障**。这不是你的问题，而是模型的“短期记忆”正在衰减。

* **对话轮次增加** → 需求开始漂移，细节逐渐被遗忘
* **上下文过长** → 注意力被稀释，幻觉概率上升
* **换新对话** → 之前的关键前提完全丢失

**结论**：Vibe Coding 在 Demo 阶段很爽，但在工程阶段是灾难。你需要一个**外部状态锁**，把意图锚定在文档里，而不是漂浮在对话里。

| 陷阱 | ❌ 错误做法 | ✅ 正确做法 |
| --- | --- | --- |
| **上下文腐烂** | 长时间维持单一对话，导致上下文过长、重点漂移。 | 用 **Spec 文档**作为锚点；必要时 New Chat 后“重喂 Spec”。 |
| **目标漂移** | "帮我优化这个函数"（结果 AI 重构了整个类） | 在 Spec 明确范围与边界；通过 **Plan** 锁定改动范围。 |
| **幻觉/瞎编接口** | 直接使用 AI 提到的 `StringUtils.sanitize()` 方法 | 用 **CodeMap/搜索**核对真实调用链；不存在就回到 Spec 修正方案。 |
| **过度信任** | 只看 AI 的文字解释："我已经修复了空指针问题" | 让 **Review 基于 Spec**做校验，并补充 ChangeLog 留痕。 |
| **一次要求太多** | "帮我实现用户注册、登录、权限管理和日志记录" | 用 Spec 拆分任务，一个 feature 一个 Spec，分批执行。 |
| **规则过拟合** | 因为一次特殊情况骂了 AI，导致 SOP 写死极端规则 | 定期 Review Spec/规则库，删除过时或过死的约束，保持可维护性。 |

**核心原则**：**AI 是很厉害的实习生，不是无需审核的高级工程师。**

**总括**：这些陷阱的本质是 **Spec 缺失或漂移**。SDD 把“对话风险”变成“文档可控”，是系统性解法。

### 4.2 进阶防守（简版）

* **倒 J 型曲线**：最后 10% 往往最耗时，避免盲目乐观。  
* **ChangeLog**：记录“文档-代码一致性”，否则无法追溯。  
* **Skill 强制化**：用脚本 + Prompt 把留痕变成强制动作。  
* **高频存档/对话归档**：深水区必须有“后悔药”。  

更完整的工程护栏与模板，已迁移到方法论篇的“进阶实践”附录：  
[《AI 原生研发范式：从“代码中心”到“文档驱动”的演进》](<AI 原生研发范式：从“代码中心”到“文档驱动”的演进.md>)。

---

## 5. 基于文档的开发流程 (Spec-Driven Development)

上面的“坑”，几乎都指向同一个解法：**把意图锚定在可审查的文档里**。

这不是“文档复古”，而是把 AI 从对话噪声中拉回**可执行协议**。没有锚点，速度就是赌；有锚点，重生成才有意义。

> **什么是 Spec-Driven Development (SDD)?** Spec-Driven Development (SDD) 是一种软件开发方法论，强调在编码开始之前编写详细、结构化的规格说明书（Specifications），通常用于指导 AI 编程代理。 它采用分阶段的方法：首先明确用户需求和意图，接着创建技术方案，将工作拆解为微小的、可审查的任务，最后逐一实施这些任务。 这一过程旨在通过提供清晰的开发蓝图，减少猜测和返工，从而显著提高代码质量、可控性和可预测性。

**定位**：SDD 是大模型时代的“保存点 (Save Point)”。它解决了三个死穴：

1. **可回溯**：随时 New Chat，满血复活；
2. **可审查**：人只看文档，不用盯几千行 Diff；
3. **可维护**：文档是资产，代码是耗材。

**为什么这很关键**：你无法保证每次都在同一个会话、同一个模型里完成工作。Spec 相当于把“意图”固化成**可传递的外部状态**，让任意模型都能在相同语境下执行。

**SDD 最小化载体**：一份可读、可审查、可复用的 Spec 文档。复杂场景再补充 CodeMap / Context / ChangeLog，但**主线永远是 Spec**。

**最小闭环三句版**：

1. 写清 Spec（目标/边界/验收）；
2. 让 AI 严格按 Spec 执行；
3. 发现问题先改 Spec，再重生成。

这套流程的**核心心法只有一句**：**文档是太阳，代码围绕文档公转**。

更完整的方法论、流程细节与 Demo 案例，已迁移到方法论篇与落地教程：  
[《AI 原生研发范式：从“代码中心”到“文档驱动”的演进》](<AI 原生研发范式：从“代码中心”到“文档驱动”的演进.md>)、  

---

## 6. 安全与合规：模型接力与仓库分级

在企业环境中，“用大模型”最容易踩坑的安全问题是：**把敏感代码或数据不加控制地丢给外部模型**。

### 6.1 简化版分级思路

| 级别 | 示例 | 模型使用原则 |
| --- | --- | --- |
| 核心机密级（高敏感） | 核心业务代码、含用户隐私的逻辑 | 禁止直接上传到公网模型；只能使用企业内部或私有化部署模型 |
| 普通级（常规） | 通用工具库、无敏感数据的 demo | 可以使用外部模型，但仍需遵守公司安全规定 |

当然还有给不同的cli、大模型和插件提供igonre，来阻止他们阅读敏感文件

### 6.2 模型接力（推荐范式）

为了兼顾安全与效果，可以采用“模型接力”：

1. **内部模型先读 & 脱敏**

    * 用内部模型阅读高密级代码，生成：
        * 架构说明 / 时序图；
        * 脱敏后的伪代码或接口描述。

2. **外部模型基于脱敏信息生成方案 / 新代码**

    * 把伪代码、接口签名和非敏感上下文交给外部高性能模型，让它：
        * 生成实现骨架；
        * 提供重构建议；
        * 写测试样例。

3. **内部验证与落地**

    * 回到内部环境，由开发者和内部大模型对照原代码落地实现；
    * 再用内部模型或人工做 Review 与回归测试。

### 6.3 高密级场景最小 Checklist（示例）

在高密级仓库中使用 AI 前，可以自查：

1. 我是否确认当前用的是 **内部/合规模型**，而不是公网接口？

2. 是否避免把以下内容发往外部：

    * 完整关键业务实现；
    * 明文密钥、账号密码、手机 / 身份证等个人信息；
    * 客户业务数据样本。

3. 是否添加了ignore文件并且强制要求cli使用。

4. 若确需借助外部模型，是否先通过内部模型或手工做了**脱敏 / 抽象（只发伪代码和接口说明）**？

5. 外部模型生成的代码，是否经过了内部 Review 和测试再合入？

## 7. 你的责任：流程设计者，而不仅是代码作者

结合前面的内容，可以把"大模型编程"理解为两层职责：

1. **个人层面**

    * 养成熟悉模型能力边界的习惯
    * 在日常开发中主动采用"测试优先 + 分步实现 + 明确约束"的工作流

2. **团队层面**

    * 设计并推广一套适合团队的"AI 使用规范"和"安全 Checklist"
    * 为不同仓库、安全等级选好默认模型和工具组合
    * 把典型案例（一次成功的 refactor、一次复杂 bug 的 AI 辅助排查）沉淀成团队经验

如果说传统编程时代，你的核心资产是“你脑子里的经验”和“你写下的代码”；那么在大模型编程时代，你最宝贵的核心资产将变成：\*\*这一整套“文档驱动的开发体系”——包括精细的需求文档、架构设计、Review 标准，以及那份会自我进化的 Prompt/SOP 库。\*\*即使哪天换了模型，换了新人，只要流程和SOP 还在，团队的战斗力就能在几分钟内恢复 80%。

这份文档只是一个起点，真正的价值会来自你在实际项目中不断试错、总结、微调的那套"你们自己的流程"
---

## 附录：常见疑问 FAQ

### Q1: 用 AI 写的代码出 Bug，责任算谁的？

**A**: 算你的。AI 是工具，你是使用者和最终 Review 者，就像用 Stack Overflow 复制的代码出问题，责任也在你。最终上线的代码质量由你负责。

### Q2: 学习 AI 编程会不会让我的编码能力退化？

**A**: 类比思考：用 IDE 自动补全不会让你忘记语法，但会让你不再记忆 API 细节。关键是**理解原理**而非**记忆语法**。AI 编程会让你：

* 更少关注"怎么写一个循环"
* 更多关注"系统架构是否合理"
* 编码能力不会退化，但能力重心会上移

### Q3: 我的代码会不会被模型拿去训练，泄露给别人？

**A**:

* **使用企业内部模型**：不会，数据不出内网
* **使用外部商业 API**（如 OpenAI、Anthropic）：大部分商业服务承诺不用 API 数据训练模型，但需查阅具体服务协议
* **使用免费在线服务**：可能会，务必查看用户协议
* **最佳实践**：核心高密级代码只用内部模型，普通代码可用外部 API

### Q4: AI 总是给出错误答案，是不是不可用？

**A**: 需要调整使用方式：

1. **明确约束**：不要问"帮我写个登录功能"，而要说"用 Spring Security + JWT 实现登录，Token 有效期 2 小时"

2. **分步验证**：不要一次生成整个模块，而是先让 AI 给方案，你确认后再分步实现

3. **主动纠错**：发现错误立即反馈给 AI："这个方法不存在，请使用项目里已有的 XxxUtils"

### Q5: 用了 AI 之后，我还需要学习新技术吗？

**A**: **必须学，而且可能要学得更快**。AI 可以帮你：

* 快速理解新框架的基本用法（"帮我解释 React Hooks 的原理"）
* 生成示例代码加速上手
* 但 AI 不能替代你的技术判断力和架构能力

反而因为 AI 降低了"实现成本"，你会有更多精力去探索新技术。

### Q6: AI 能完全取代程序员吗？

**A**: 不能，至少在可预见的未来不行。AI 在很多重复性、模式化、实现层面的工作上确实已经可以做到比普通工程师更稳定、更高效，但它有几个天然短板：

* 很难真正理解那些含糊、暧昧、不断变化的产品需求，只能根据你给的描述去“猜”；
* 无法主动协调多个子系统、多个 Sub AI 以及跨团队沟通，它只能在你设计好的流程里执行；
* 最关键的一点：它没法为线上事故和业务决策背锅，也承担不了合规和安全责任。

所以更现实的图景是：**能熟练驾驭 AI 的工程师会替代不会用 AI 的工程师**，而不是“AI 整体替代所有程序员”。你的不可替代之处在于理解业务、拆解问题、设计流程，以及为结果负责——AI 帮你干活，但短期内还抢不走你的饭碗。

### Q7: 使用大模型效率提升了，团队是不是应该承担双倍的需求吞吐量？

**A: 这是一个需要高度警惕的“效率陷阱”。**

虽然 AI 加快了“编码（Coding）”的速度，但它并没有缩短“思考（Thinking）”、“审查（Reviewing）”和“验证（Testing）”的时间。相反，**AI 生成代码的速度越快，代码审查的密度要求就越高。**

如果因为 AI 写得快，就盲目将需求吞吐量翻倍，会导致两个严重的后果：

1. **“泡沫代码”堆积**：AI 极易生成“看起来能跑但逻辑脆弱”的代码。如果没有足够的人工 Review 时间，这些代码会迅速变成难以维护的“技术债”。

2. **风控防线失效**：当排期被压缩到只能“由 AI 生成并直接提交”时，工程师实际上失去了对系统的掌控力。一旦发生线上故障，修复成本将指数级上升。

**结论**：AI 节省下来的时间，**不应被全部转化为“更多的功能数量”**，而应被重新投资到**“更高的代码质量”和“更完备的测试覆盖”**上。这才是实现降本增效（降低维护成本，增加开发效率）的正确路径。

可以快速落地的方法论也出啦：

[《AI 原生研发范式：从“代码中心”到“文档驱动”的演进》](<AI 原生研发范式：从“代码中心”到“文档驱动”的演进.md>)

## 注：以上图片均由Gemini3制作，内容由GP5.1、Gemini3、Qwen生成。企业内网核心代码均由内部版大模型操作，开源项目由Claude4.5和GPT5.1操作
